{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is necessary to run this notebook Python 2.x\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make the figures display in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# set the gray colormap and turn off image interpolation\n",
    "# make sure numpy is imported\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Image filtering theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Filtering is one of the most basic and common image operations in image processing. You can filter an image to remove noise or to enhance features. To understand filtering, it helps to start with a 1D signal, instead of an image. Indeed the word \"filtering\" comes from electrical signal processing, where physical devices would filter out (remove) particular features of a signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Local filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The \"local\" in local filtering simply means that a pixel is adjusted by looking at values surrounding that pixel. The surrounding elements that are used are defined by the filter's \"footprint\", \"structuring element\", or \"kernel\". (These terms are, sadly, used more or less interchangeably.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "step_signal = np.zeros(100)\n",
    "step_signal[33:67] = 1\n",
    "plt.plot(step_signal)\n",
    "plt.margins(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to find out when the signal turns on or off. The naive approach would be to write a for-loop to look at each position and adjacent position to determine where they differ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "changes = []\n",
    "for i in range(len(step_signal) - 1):\n",
    "    if step_signal[i] != step_signal[i+1]:\n",
    "        changes.append(i)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way is to use a bit of numpy indexing and arithmetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "diff = step_signal[:-1] - step_signal[1:]\n",
    "changes = np.flatnonzero(diff)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And yet another way is to use a *difference filter*, which abstracts away the indexing step above.\n",
    "\n",
    "In convolution, at every point of the *signal*, we\n",
    "place the *filter* and produce the dot-product of the (reversed) filter against\n",
    "the signal values preceding that location:\n",
    "$s'(t) = \\sum_{j=t-\\tau}^{t}{s(j)f(t-j)}$\n",
    "where $s$ is the signal, $s'$ is the filtered signal, $f$ is the filter, and\n",
    "$\\tau$ is the length of the filter.\n",
    "\n",
    "Now, think of what happens when the filter is (1, -1), the difference filter:\n",
    "when adjacent values (u, v) of the signal are identical, the filter produces\n",
    "-u + v = 0. But when v > u, the signal produces some positive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "kernel = [1, -1]\n",
    "diff = ndi.convolve(step_signal, kernel)\n",
    "plt.plot(diff)\n",
    "\n",
    "changes = np.flatnonzero(diff)\n",
    "print(changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "However, signals are usually a bit noisier than this. Let's see what happens when we add a bit of noise to the signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "noisy_signal = step_signal + np.random.normal(0, 0.1, size=step_signal.shape)\n",
    "plt.plot(noisy_signal)\n",
    "plt.margins(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The simplest way to recover something that looks a bit more like the original signal is to average out the noise using neighbouring points in the signal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Take the mean of neighboring points\n",
    "smooth_signal = (noisy_signal[:-2] + noisy_signal[1:-1] + noisy_signal[2:]) / 3\n",
    "plt.plot(smooth_signal)\n",
    "plt.margins(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As with the edge filter, we can use a *mean filter* and `ndi.convolve` to achieve the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean_kernel = np.array([1, 1, 1]) / 3.0\n",
    "smooth_signal = np.convolve(noisy_signal, mean_kernel)\n",
    "plt.plot(smooth_signal)\n",
    "plt.margins(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Local filtering of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "These concepts expand naturally to 2D images. Let's start with an incredibly simple image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bright_square = np.zeros((7, 7), dtype=float)\n",
    "bright_square[2:5, 2:5] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This gives the values below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(bright_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "and looks like a white square centered on a black square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(bright_square);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The mean filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For our first example of a filter, consider the following filtering array, which we'll call a \"mean kernel\". For each pixel, a kernel defines which neighboring pixels to consider when filtering, and how much to weight those pixels.\n",
    "\n",
    "Note, there is one difference with the above 1D filters: the kernels we will use from now on are *centered*: their length is an odd number so that each pixel is replaced by a function of its neighborhood. Above, we weren't looking at the pixels, but at the space between them. Centered filters are generally easier to work with, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mean_kernel = np.ones((3, 3)) / 9\n",
    "\n",
    "print(mean_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now, let's take our mean kernel and apply it to every pixel of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Applying a (linear) filter essentially means:\n",
    "* Center a kernel on a pixel\n",
    "* Multiply the pixels *under* that kernel by the values *in* the kernel\n",
    "* Sum all the those results\n",
    "* Replace the center pixel with the summed result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This process is known as convolution. Let's actually walk through an example of this process below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import skdemo\n",
    "skdemo.mean_filter_interactive_demo(bright_square)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's take a look at the numerical result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# set floating point display precision\n",
    "%precision 2\n",
    "print(ndi.convolve(bright_square, mean_kernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The meaning of \"mean kernel\" should be clear now: Each pixel was replaced with the mean value within the 3x3 neighborhood of that pixel. When the kernel was over `n` bright pixels, the pixel in the kernel's center was changed to n/9 (= n * 0.111). When no bright pixels were under the kernel, the result was 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This filter is a simple smoothing filter and produces two important results:\n",
    "1. The intensity of the bright pixel decreased.\n",
    "2. The intensity of the region near the bright pixel increased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Slight aside:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "print(mean_kernel.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note that all the values of the kernel sum to 1. Why might that be important? Sure, a definition of a mean requires this property, but why might this be a favorable property for many image filters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Downsampled image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's consider a real image now. It'll be easier to see some of the filtering we're doing if we downsample the image a bit. We can slice into the image using the \"step\" argument to sub-sample it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "\n",
    "image = data.camera()\n",
    "pixelated = image[::10, ::10]\n",
    "skdemo.imshow_all(image, pixelated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here we use a step of 10, giving us every tenth column and every tenth row of the original image. You can see the highly pixelated result on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean filter on a real image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we can apply the filter to this downsampled image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "filtered = ndi.convolve(pixelated, mean_kernel)\n",
    "skdemo.imshow_all(pixelated, filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Comparing the filtered image to the pixelated image, we can see that this filtered result is smoother: Sharp edges (which are just borders between dark and bright pixels) are smoothed because dark pixels reduce the intensity of neighboring pixels and bright pixels do the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Essential filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "If you read through the last section, you're already familiar with the essential concepts of image filtering. But, of course, you don't have to create custom filter kernels for all of your filtering needs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Gaussian filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The classic image filter is the Gaussian filter. This is similar to the mean filter, in that it tends to smooth images. The Gaussian filter, however, doesn't weight all values in the neighborhood equally. Instead, pixels closer to the center are weighted more than those farther away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "# For skimage versions on or before 0.10, comment the line above\n",
    "# and uncomment the one below\n",
    "#import skimage.filter as filters\n",
    "\n",
    "sigma = 1\n",
    "smooth = filters.gaussian_filter(bright_square, sigma)\n",
    "skdemo.imshow_all(bright_square, smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For the Gaussian filter, `sigma`, the standard deviation, defines the size of the neighborhood.\n",
    "\n",
    "For a real image, we get the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "# The Gaussian filter returns a float image, regardless of input.\n",
    "# Cast to float so the images have comparable intensity ranges.\n",
    "pixelated_float = img_as_float(pixelated)\n",
    "smooth = filters.gaussian_filter(pixelated_float, 1)\n",
    "skdemo.imshow_all(pixelated_float, smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This doesn't look drastically different than the mean filter, but the Gaussian filter is typically preferred because of the distance-dependent weighting. For a more detailed image and a larger filter, you can see artifacts in the mean filter since it doesn't take distance into account:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "size = 20\n",
    "structuring_element = np.ones((3*size, 3*size))\n",
    "smooth_mean = filters.rank.mean(image, structuring_element)\n",
    "smooth_gaussian = filters.gaussian_filter(image, size)\n",
    "titles = ['mean', 'gaussian']\n",
    "skdemo.imshow_all(smooth_mean, smooth_gaussian, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The size of the structuring element used for the mean filter and the size (standard deviation) of the Gaussian filter are tweaked to produce an approximately equal amount of smoothing in the two results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Difference filters in 2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "For images, you can think of an edge as points where the gradient is large in one direction. We can approximate gradients with difference filters. There are many ways to compute intensity differences between neighboring pixels (by weighting neighbors differently). At its simplest, you can just subtract one neighbor from the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## <span style=\"color:cornflowerblue\">Exercise:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Create a simple difference filter to **find the horizontal or vertical edges** of an image. Try to ensure that the filtering operation doesn't shift the edge position. (Don't use slicing to produce the difference image; use convolution.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This should get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Replace the kernels below with your difference filter\n",
    "# `ones` is used just for demonstration and your kernel \n",
    "# should be larger than (1, 1)\n",
    "horizontal_edge_kernel = np.ones((1, 1))\n",
    "vertical_edge_kernel = np.ones((1, 1))\n",
    "\n",
    "# As discussed earlier, you may want to replace pixelated\n",
    "# with a different image.\n",
    "image = pixelated\n",
    "# NOTE: A **vertical** gradient has a strong response at \n",
    "# **horizontal** edges and vice versa.\n",
    "vertical_gradient = ndi.convolve(image, horizontal_edge_kernel)\n",
    "horizontal_gradient = ndi.convolve(image, vertical_edge_kernel)\n",
    "skdemo.imshow_all(horizontal_gradient, vertical_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sobel edge filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The Sobel filter, the most commonly used edge filter, should look pretty similar to what you developed above. Take a look at the vertical and horizontal components of the Sobel kernel to see how they differ from your earlier implementation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* http://scikit-image.org/docs/dev/api/skimage.filter.html#vsobel\n",
    "* http://scikit-image.org/docs/dev/api/skimage.filter.html#hsobel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The standard Sobel filter gives the gradient magnitude. This is similar to what we saw above, except that horizontal and vertical components are combined such that the direction of the gradient is ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "skdemo.imshow_all(bright_square, filters.sobel(bright_square))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notice that the size of the output matches the input, and the edges aren't preferentially shifted to a corner of the image. Furthermore, the weights used in the Sobel filter produce diagonal edges with reponses that are comparable to horizontal or vertical edges.\n",
    "\n",
    "Like any derivative, noise can have a strong impact on the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pixelated_gradient = filters.sobel(pixelated)\n",
    "skdemo.imshow_all(pixelated, pixelated_gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Smoothing is often used as a preprocessing step in preparation for feature detection and image-enhancement operations because sharp features can distort results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gradient = filters.sobel(smooth)\n",
    "titles = ['gradient before smoothing', 'gradient after smoothing']\n",
    "# Scale smoothed gradient up so they're of comparable brightness.\n",
    "skdemo.imshow_all(pixelated_gradient, gradient*1.8, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notice how the edges look more continuous in the smoothed image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## <span style=\"color:cornflowerblue\">Exercise:</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Using the filter kernels from the `vsobel` and `hsobel` documentation, **find the direction of the maximum gradient** in an image. Here's some code to get you started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Kernel copied from `vsobel` docstring.\n",
    "# Vertical edge-reponse is the *horizontal* gradient.\n",
    "dx_kernel = np.array([\n",
    "    [1,   0,  -1],\n",
    "    [2,   0,  -2],\n",
    "    [1,   0,  -1],\n",
    "])\n",
    "# Rotate array by 90 degrees to get y-gradient kernel\n",
    "dy_kernel = np.rot90(dx_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "And here are some test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "image_45 = np.tril(-np.ones([7, 7]))  # lower triangle of the given matrix\n",
    "image_135 = np.rot90(image_45)\n",
    "skdemo.imshow_all(image_45, image_135)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "`scikit-image` also provides more sophisticated filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# If this import fails for you, you're probably using an old version\n",
    "# Instead, use: from skimage.filter import denoise_tv_bregman\n",
    "from skimage.restoration import denoise_tv_bregman\n",
    "denoised = denoise_tv_bregman(image, 4)\n",
    "titles = ['image', 'denoised']\n",
    "skdemo.imshow_all(image, denoised, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [Denoising examples](http://scikit-image.org/docs/dev/auto_examples/plot_denoise.html)\n",
    "* [Rank filters example](http://scikit-image.org/docs/dev/auto_examples/applications/plot_rank_filters.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div style=\"height: 400px;\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".rendered_html {\n",
       "    font-family: Georgia, serif;\n",
       "    font-size: 130%;\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".input {\n",
       "    width: 930px;\n",
       "}\n",
       "\n",
       ".inner_cell {\n",
       "    width: 800px;\n",
       "}\n",
       "\n",
       ".code_cell {\n",
       "    width: 800px;\n",
       "}\n",
       "\n",
       ".CodeMirror-sizer {\n",
       "}\n",
       "\n",
       "hr {\n",
       "    border: 1px solid #DDD;\n",
       "}\n",
       "\n",
       ".rendered_html h1 {\n",
       "    margin: 0.25em 0em 0.5em;\n",
       "    font-family: sans-serif;\n",
       "    color: #015C9C;\n",
       "    text-align: center;\n",
       "    line-height: 1.2;\n",
       "    page-break-before: always;\n",
       "}\n",
       "\n",
       ".rendered_html h2 {\n",
       "    margin: 1.1em 0em 0.5em;\n",
       "    font-family: sans-serif;\n",
       "    color: #26465D;\n",
       "    line-height: 1.2;\n",
       "}\n",
       "\n",
       ".rendered_html h3 {\n",
       "    font-family: sans-serif;\n",
       "    margin: 1.1em 0em 0.5em;\n",
       "    color: #002845;\n",
       "    line-height: 1.2;\n",
       "}\n",
       "\n",
       ".rendered_html li {\n",
       "    line-height: 1.5;\n",
       "}\n",
       "\n",
       ".CodeMirror-lines {\n",
       "    font-size: 110%;\n",
       "    line-height: 1.4em;\n",
       "    font-family: DejaVu Sans Mono, Consolas, Ubuntu, monospace;\n",
       "}\n",
       "\n",
       "h1.bigtitle {\n",
       "    margin: 4cm 1cm 4cm 1cm;\n",
       "    font-size: 300%;\n",
       "}\n",
       "\n",
       "h3.point {\n",
       "    font-size: 200%;\n",
       "    text-align: center;\n",
       "    margin: 2em 0em 2em 0em;\n",
       "    #26465D\n",
       "}\n",
       "\n",
       ".logo {\n",
       "    margin: 20px 0 20px 0;\n",
       "}\n",
       "\n",
       "a.anchor-link {\n",
       "    display: none;\n",
       "}\n",
       "\n",
       "h1.title {\n",
       "    font-size: 250%;\n",
       "}\n",
       "\n",
       ".exercize {\n",
       "    color: #738;\n",
       "}\n",
       "\n",
       "h2 .exercize {\n",
       "    font-style: italic;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext load_style\n",
    "%load_style ../themes/tutorial.css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
